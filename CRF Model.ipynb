{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install --yes --prefix {sys.prefix} pytorch torchvision torchaudio -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-crf in /Users/seankohlbrenner/anaconda3/lib/python3.8/site-packages (0.7.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pytorch-crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchcrf import CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_label_file, test_label_file, train_data_file, test_data_file):\n",
    "    PATH_TO_SAVED_DATA = os.getcwd() + \"/Processed Data/\"\n",
    "\n",
    "    # Load Data\n",
    "    training_labels = pickle.load(open(PATH_TO_SAVED_DATA + train_label_file, \"rb\"))\n",
    "    testing_labels = pickle.load(open(PATH_TO_SAVED_DATA + test_label_file, \"rb\"))\n",
    "    training_data = pickle.load(open(PATH_TO_SAVED_DATA + train_data_file, \"rb\"))\n",
    "    testing_data = pickle.load(open(PATH_TO_SAVED_DATA + test_data_file, \"rb\"))\n",
    "    \n",
    "    # Convert labels to same format as data\n",
    "    training_labels = np.asarray([[label] for label in training_labels])\n",
    "    testing_labels = np.asarray([[label] for label in testing_labels])\n",
    "    \n",
    "    # Duplicate labels to the length of the sequence\n",
    "    # Turns the label into a \"tag\"\n",
    "    training_labels = np.repeat(training_labels, len(training_data[0]), axis=1)\n",
    "    testing_labels = np.repeat(testing_labels, len(testing_data[0]), axis=1)\n",
    "    \n",
    "    linear_training_data = training_data\n",
    "    linear_testing_data = testing_data\n",
    "    \n",
    "    training_data = np.expand_dims(training_data, axis=2)\n",
    "    testing_data = np.expand_dims(testing_data, axis=2)\n",
    "    \n",
    "    # Convert data and labels to tensors\n",
    "    dtype = torch.FloatTensor\n",
    "    training_data = Variable(torch.from_numpy(training_data).type(dtype), requires_grad=False)\n",
    "    training_labels = Variable(torch.from_numpy(training_labels).type(dtype), requires_grad=False)\n",
    "    testing_data = Variable(torch.from_numpy(testing_data).type(dtype), requires_grad=False)\n",
    "    testing_labels = Variable(torch.from_numpy(testing_labels).type(dtype), requires_grad=False)\n",
    "    \n",
    "    linear_training_data = Variable(torch.from_numpy(linear_training_data).type(dtype), requires_grad=False)\n",
    "    linear_testing_data = Variable(torch.from_numpy(linear_testing_data).type(dtype), requires_grad=False)\n",
    "\n",
    "    #testing_data = \n",
    "    #training_labels = \n",
    "    #testing_labels = \n",
    "    \n",
    "    # Print confirmation of data and label size\n",
    "    print(\"Training labels size:\", training_labels.size())\n",
    "    print(\"Testing labels size:\", testing_labels.size())\n",
    "    print(\"Training data size:\", training_data.size())\n",
    "    print(\"Testing data size:\", testing_data.size())\n",
    "    print(\"Linear training data size:\", linear_training_data.size())\n",
    "    print(\"Linear testing data size:\", linear_testing_data.size())\n",
    "    \n",
    "    \n",
    "    return training_labels, testing_labels, training_data, testing_data, linear_training_data, linear_testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels size: torch.Size([3496, 105])\n",
      "Testing labels size: torch.Size([1498, 105])\n",
      "Training data size: torch.Size([3496, 105, 1])\n",
      "Testing data size: torch.Size([1498, 105, 1])\n",
      "Linear training data size: torch.Size([3496, 105])\n",
      "Linear testing data size: torch.Size([1498, 105])\n",
      "tensor([[0.0760, 0.0000, 0.4354,  ..., 0.0156, 0.0625, 0.0313],\n",
      "        [0.0760, 0.0000, 0.4354,  ..., 0.0625, 0.0313, 0.1250],\n",
      "        [0.0760, 0.0000, 0.4354,  ..., 0.0625, 0.0781, 0.0625],\n",
      "        ...,\n",
      "        [0.0640, 0.0000, 0.4644,  ..., 0.0664, 0.0859, 0.1172],\n",
      "        [0.0580, 1.0000, 0.4634,  ..., 0.2344, 0.1875, 0.0781],\n",
      "        [0.0000, 1.0000, 0.4495,  ..., 0.1758, 0.1641, 0.1328]])\n",
      "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0.0590, 1.0000, 0.5003,  ..., 0.1250, 0.2188, 0.1563],\n",
      "        [0.0590, 1.0000, 0.5003,  ..., 0.1406, 0.2344, 0.2031],\n",
      "        [0.0590, 1.0000, 0.5003,  ..., 0.1094, 0.1406, 0.1406],\n",
      "        ...,\n",
      "        [0.0740, 1.0000, 0.4605,  ..., 0.0938, 0.0781, 0.0781],\n",
      "        [0.0650, 0.0000, 0.4525,  ..., 0.1025, 0.0918, 0.0762],\n",
      "        [0.0740, 1.0000, 0.4605,  ..., 0.1484, 0.1328, 0.1875]])\n",
      "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([3496, 105])\n",
      "torch.Size([1498, 105])\n"
     ]
    }
   ],
   "source": [
    "train_labels, test_labels, train_data, test_data, lin_train_data, lin_test_data = load_data(\"train_labels.p\", \n",
    "                                                                                            \"test_labels.p\", \n",
    "                                                                                            \"train_data.p\", \n",
    "                                                                                            \"test_data.p\")\n",
    "\n",
    "#lin_train_data = lin_train_data.narrow(1, 0, 15)\n",
    "#lin_test_data = lin_test_data.narrow(1, 0, 15)\n",
    "\n",
    "#train_labels = train_labels.narrow(1, 0, 15)\n",
    "#test_labels = test_labels.narrow(1, 0, 15)\n",
    "\n",
    "print(lin_train_data)\n",
    "print(train_labels)\n",
    "print(lin_test_data)\n",
    "print(test_labels)\n",
    "print(lin_train_data.shape)\n",
    "print(lin_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphResults(epoch, loss, f1, auc):\n",
    "    \"\"\"Graph the loss, f1 score, and AUC over each epoch during training.\n",
    "    \n",
    "    Keyword arguments:\n",
    "    epoch -- the number of training iterations\n",
    "    loss -- array of size [epoch] containing the loss value of each iteration\n",
    "    f1 -- array of size [epoch] contianing the f1 value of each iteration\n",
    "    auc -- array of size [epoch] contianing the auc of each iteration\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    iterations = np.arange(epoch)\n",
    "    plt.plot(iterations, loss)\n",
    "    plt.title(\"Loss During Training\")\n",
    "\n",
    "    plt.figure()\n",
    "    iterations = np.arange(epoch)\n",
    "    plt.plot(iterations, f1)\n",
    "    plt.title(\"F1 During Training\")\n",
    "    \n",
    "    plt.figure()\n",
    "    iterations = np.arange(epoch)\n",
    "    plt.plot(iterations, auc)\n",
    "    plt.title(\"AUC During Training\")\n",
    "\n",
    "    print(\"Best F1 Epoch:\", list(f1).index(max(f1)))\n",
    "    print(\"Best AUC Epoch:\", list(auc).index(max(auc)))\n",
    "    \n",
    "\n",
    "def test_crf(model, emissions, test_labels):\n",
    "    y_pred = model.predict(emissions, test_labels)\n",
    "    y_pred = np.asarray([((sum(i) / 105) * 65) for i in y_pred])\n",
    "    y_score = y_pred\n",
    "    y_pred = y_pred >= 0.5\n",
    "    y_pred = y_pred.astype(int)\n",
    "    y_true = np.asarray(test_labels.detach().numpy())\n",
    "    y_true = [i[0] for i in y_true]\n",
    "    \n",
    "    return y_true, y_pred, y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRF_Model(nn.Module):\n",
    "    def __init__(self, batch_size, seq_len, num_tags):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.seq_len = seq_len\n",
    "        self.num_tags = num_tags\n",
    "        \n",
    "        # Linear model to calculate emissions\n",
    "        self.linear = nn.Linear(self.seq_len, self.seq_len)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        # CRF tagger\n",
    "        self.crf = CRF(num_tags, batch_first=True)\n",
    "    \n",
    "    def predict(self, x_lin, y):\n",
    "        y_pred = self.linear(x_lin)\n",
    "        y_pred = self.sigmoid(y_pred)\n",
    "        \n",
    "        emissions = torch.unsqueeze(y_pred, 2)\n",
    "        \n",
    "        # Convert emissions final dimension to 2\n",
    "        # where the final dimension: [P(y=0|x), P(y=1|x)]\n",
    "        emissions = torch.cat((emissions, y.unsqueeze(2)), dim=-1)\n",
    "        for i in range(len(emissions)):\n",
    "            for j in range(len(emissions[i])):\n",
    "                if emissions[i][j][0] < torch.Tensor([0.5]):\n",
    "                    emissions[i][j][1] = torch.sub(torch.Tensor([1]), emissions[i][j][0])\n",
    "                else:\n",
    "                    emissions[i][j][1] = emissions[i][j][0]\n",
    "                    emissions[i][j][0] = torch.sub(torch.Tensor([1]), emissions[i][j][1])\n",
    "        \n",
    "        #y = y.type(torch.LongTensor)\n",
    "        \n",
    "        y_pred = self.crf.decode(emissions)\n",
    "        return y_pred\n",
    "\n",
    "    def loss(self, x_lin, y):\n",
    "        y_pred = self.linear(x_lin)\n",
    "        y_pred = self.sigmoid(y_pred)\n",
    "        \n",
    "        emissions = torch.unsqueeze(y_pred, 2)\n",
    "        \n",
    "        # Convert emissions final dimension to 2\n",
    "        # where the final dimension: [P(y=0|x), P(y=1|x)]\n",
    "        emissions = torch.cat((emissions, y.unsqueeze(2)), dim=-1)\n",
    "        for i in range(len(emissions)):\n",
    "            for j in range(len(emissions[i])):\n",
    "                if emissions[i][j][0] < torch.Tensor([0.5]):\n",
    "                    emissions[i][j][1] = torch.sub(torch.Tensor([1]), emissions[i][j][0])\n",
    "                else:\n",
    "                    emissions[i][j][1] = emissions[i][j][0]\n",
    "                    emissions[i][j][0] = torch.sub(torch.Tensor([1]), emissions[i][j][1])\n",
    "        \n",
    "        y = y.type(torch.LongTensor)\n",
    "        \n",
    "        log_likelihood = self.crf.forward(emissions, y)\n",
    "        return -log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 295987.90625\n",
      "Confusion Matrix:\n",
      " [[749   0]\n",
      " [745   4]]\n",
      "Recall: 1.0\n",
      "Accuracy:  0.5026702269692924\n",
      "AUC:       0.4993342257856937\n",
      "1 21597935616.0\n",
      "Confusion Matrix:\n",
      " [[  0 749]\n",
      " [  0 749]]\n",
      "Recall: 0.0\n",
      "Accuracy:  0.5\n",
      "AUC:       0.5\n",
      "2 44510953472.0\n",
      "Confusion Matrix:\n",
      " [[749   0]\n",
      " [749   0]]\n",
      "Recall: 1.0\n",
      "Accuracy:  0.5\n",
      "AUC:       0.5\n"
     ]
    }
   ],
   "source": [
    "batch_size = len(train_data)\n",
    "seq_len = len(train_data[0])\n",
    "num_tags = len(train_data[0][0]) + 1\n",
    "\n",
    "model = CRF_Model(batch_size, seq_len, num_tags)\n",
    "\n",
    "models = []\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-6)\n",
    "\n",
    "\n",
    "for epoch in range(3):\n",
    "    # Forward pass to compute predictions using training_data\n",
    "    #print(\"Forward Pass\")\n",
    "    loss = model.loss(lin_train_data, train_labels)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        print(epoch, loss.item())\n",
    "        \n",
    "    y_true, y_pred, y_score = test_crf(model, lin_test_data, test_labels)\n",
    "    confusion_matrix = metrics.confusion_matrix(y_true, y_pred, labels=[1,0])\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix)\n",
    "    recall = metrics.recall_score(y_true, y_pred)\n",
    "    print(\"Recall:\", recall)\n",
    "    accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    auc = metrics.roc_auc_score(y_true, y_score)\n",
    "    print(\"AUC:      \", auc)\n",
    "    \n",
    "    models.append(copy.deepcopy(model))\n",
    "\n",
    "    # Zero gradients, perform backward pass, and update weights\n",
    "    #print(\"Zero Gradients\")\n",
    "    model.zero_grad()\n",
    "    #print(\"Backward Pass\")\n",
    "    loss.backward()\n",
    "    #print(\"Update Weights\")\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_models.append(models[0])\n",
    "len(saved_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred, y_score = test_crf(saved_models[14], lin_test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:    0.7797062750333779\n",
      "Accuracy:  0.6608811748998665\n",
      "AUC:       0.6822875538546278\n"
     ]
    }
   ],
   "source": [
    "#confusion_matrix = metrics.confusion_matrix(y_true, y_pred, labels=[1,0])\n",
    "#print(\"Confusion Matrix:\\n\", confusion_matrix)\n",
    "\n",
    "recall = metrics.recall_score(y_true, y_pred)\n",
    "print(\"Recall:   \", recall)\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "#precision = metrics.precision_score(y_true, y_pred)\n",
    "#print(\"Precision:\", precision)\n",
    "\n",
    "#f1 = metrics.f1_score(y_true, y_pred)\n",
    "#print(\"F1:       \", f1)\n",
    "\n",
    "auc = metrics.roc_auc_score(y_true, y_score)\n",
    "print(\"AUC:      \", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CRF_recall.append(recall)\n",
    "CRF_accuracy.append(accuracy)\n",
    "CRF_auc.append(auc)\n",
    "\n",
    "len(CRF_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd() + \"/Results/\"\n",
    "pickle.dump(saved_models, open(path + \"CRF_Models.p\", \"wb\"))\n",
    "pickle.dump(CRF_recall, open(path + \"CRF_recall.p\", \"wb\"))\n",
    "pickle.dump(CRF_accuracy, open(path + \"CRF_accuracy.p\", \"wb\"))\n",
    "pickle.dump(CRF_auc, open(path + \"CRF_auc.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

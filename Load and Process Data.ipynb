{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Data Format:\n",
    "### User Data:\n",
    "\n",
    "BirthYear | Gender | Parkinsons | Tremors | DiagnosisYear | Sided | UPDRS | Impact | Levadopa | DA | MAOB | Other\n",
    "\n",
    "### Tappy Data\n",
    "\n",
    "UserKey | Date | Timestamp | Hand | Hold Time | Direction | Latency Time | Flight Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processed Data Format\n",
    "\n",
    "## Data Decisions\n",
    "\n",
    "\n",
    "Of all the users I select those that have the following characteristics (similar to previous study):\n",
    "\n",
    "- Severity = Mild (Of those with PD)\n",
    "    - Becuase the point is early diagnosis\n",
    "- Medicatied = False\n",
    "    - To avoid the interaction dopamine inhibitors will have on tremors\n",
    "    \n",
    "    \n",
    "## Processed Data\n",
    "\n",
    "Of the data that has the previous characteristics I include the following information:\n",
    "\n",
    "| Parkinsons | Age | Gender | Date | Timestamp | Hand | Hold Time | Direction | Latency Time | Flight Time |\n",
    "\n",
    "I leave out the following data so the processed data includes information someone not diagnosed with PD would know/information a program could easily pick up:\n",
    "\n",
    "- Tremors\n",
    "- Diagnosis Year\n",
    "- Sided\n",
    "- UPDRS\n",
    "- Impact\n",
    "- Levadopa\n",
    "- DA\n",
    "- MAOB\n",
    "- Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process User Data\n",
    "\n",
    "Since there can be multiple \"tappy\" records for a single participant, I'll first get information from each of them\n",
    "\n",
    "I will save the data in a dictionary:\n",
    " {UserID: dataframe}\n",
    " \n",
    "As per the contraints laid out previously the dataframe will include the following:\n",
    "\n",
    "- Parkinsons (0 if no, 1 if yes)\n",
    "- Birth Year\n",
    "- Gender (0 if male, 1 if female)\n",
    "- Impact (0 if mild, 1 if moderate, 2 if severe, -1 if unknown)\n",
    "- Medicated (0 if no, 1 if yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    58\n",
       "1    14\n",
       "Name: Parkinsons, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_TO_USERS = os.getcwd() + \"/Tappy Data/Users/\"\n",
    "\n",
    "# Useful lines of user data file\n",
    "BIRTH_YEAR = 0\n",
    "GENDER = 1\n",
    "PARKINSONS = 2\n",
    "IMPACT = 7\n",
    "LEVADOPA = 8\n",
    "DA = 9\n",
    "MAOB = 10\n",
    "OTHER = 11\n",
    "\n",
    "def getUserFromFileName(filename):\n",
    "    filename = filename[5:]\n",
    "    return filename[:-4]\n",
    "    \n",
    "def createUserRow(filepath, user_id):\n",
    "    \"\"\"\n",
    "    Extract data from user file at filepath.\n",
    "    \n",
    "    Creates and returns a dataframe with: \n",
    "        Parkinsons | BirthYear | Gender | Impact| Medicated\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    filepath - string, path to user file\n",
    "    \"\"\"\n",
    "    ## Get user file ##\n",
    "    f = open(filepath, 'r')\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    #pprint(lines)\n",
    "    \n",
    "    ## Extract data ##\n",
    "    parkinsons = 0\n",
    "    birth_year = 0\n",
    "    gender = 0\n",
    "    impact = -1\n",
    "    medicated = 0\n",
    "    \n",
    "    # Parkinsons\n",
    "    if \"True\" in lines[PARKINSONS]: parkinsons = 1\n",
    "    \n",
    "    # Birth Year\n",
    "    year = [int(s) for s in lines[BIRTH_YEAR].split() if s.isdigit()]\n",
    "    if year: birth_year = year[0]\n",
    "    \n",
    "    # Gender\n",
    "    if \"Female\" in lines[GENDER]: gender = 1\n",
    "        \n",
    "    # Impact\n",
    "    if \"Mild\" in lines[IMPACT][8:]: impact = 0\n",
    "    elif \"Med\" in lines[IMPACT][8:]: impact = 1\n",
    "    elif \"Sev\" in lines[IMPACT][8:]: impact = 2\n",
    "    \n",
    "    # Medicated\n",
    "    if \"True\" in lines[LEVADOPA]: medicated = 1\n",
    "    elif \"True\" in lines[DA]: medicated = 1\n",
    "    elif \"True\" in lines[MAOB]: medicated = 1\n",
    "    elif \"True\" in lines[OTHER]: medicated = 1\n",
    "    \n",
    "    return [user_id, parkinsons, birth_year, gender, impact, medicated]\n",
    "\n",
    "\n",
    "users = [f for f in os.listdir(PATH_TO_USERS)]\n",
    "\n",
    "column_names = [\"UserID\", \"Parkinsons\", \"BirthYear\", \"Gender\", \"Impact\", \"Medicated\"]\n",
    "all_users = pd.DataFrame(columns=column_names)\n",
    "\n",
    "i = 0\n",
    "for user in users:\n",
    "    all_users.loc[i] = createUserRow(PATH_TO_USERS + user, getUserFromFileName(user))\n",
    "    i += 1\n",
    "    \n",
    "pd.set_option('display.max_rows', 230)\n",
    "\n",
    "all_users.set_index(\"UserID\", inplace=True)\n",
    "\n",
    "selected_users = all_users[all_users[\"Impact\"] < 1]\n",
    "selected_users = selected_users[selected_users[\"Medicated\"] == 0]\n",
    "\n",
    "#selected_users[\"Parkinsons\"].value_counts()\n",
    "\n",
    "selected_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save/Load User Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_SAVED_DATA = os.getcwd() + \"/Processed Data/\"\n",
    "\n",
    "# Save\n",
    "#pickle.dump(all_users, open(PATH_TO_SAVED_DATA + \"all_users.p\", \"wb\"))\n",
    "#pickle.dump(selected_users, open(PATH_TO_SAVED_DATA + \"selected_users.p\", \"wb\"))\n",
    "\n",
    "# Load\n",
    "#all_users = pickle.load(open(PATH_TO_SAVED_DATA + \"all_users.p\", \"rb\"))\n",
    "selected_users = pickle.load(open(PATH_TO_SAVED_DATA + \"selected_users.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Keystroke Data\n",
    "\n",
    "Using the selected users produce 2 numpy arrays:\n",
    "\n",
    "1. Labels\n",
    "    \n",
    "    Ex: \\[0, 1, 0, 0, 0, 1, 0, 1, 1, 0, ...\\]\n",
    "    \n",
    "    Length = # participants\n",
    "\n",
    "\n",
    "2. Sequence Data\n",
    "    \n",
    "    Sequence data = \\[Sequence 1, Sequence  2, ..., Sequence 11107\\]\n",
    "    \n",
    "    Each sequence = \\[Observation 1, Observation 2, ..., Observation 250\\]\n",
    "    \n",
    "    Each observation = \\[Age, Gender, Hand, HoldTime, Direction, LatencyTime, FlightTime\\]\n",
    "\n",
    "\n",
    "2. Feature Data\n",
    "\n",
    "    Each sequence is comprised of a set of features\n",
    "    \n",
    "    | Age | Gender | % Left hand usage | Mean flight | Mean latency | hold1 | hold2 | ... | hold 250 |\n",
    "    \n",
    "    **This means that the input size is now 255**\n",
    "    \n",
    "\n",
    "**Note:** Each sequence laid out above corresponds to 250 observation subsets/time steps of one month of a user's collected data\n",
    "\n",
    "* Sample/Batch size = 11106\n",
    "\n",
    "* Time Steps = 250\n",
    "\n",
    "* Features = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_KEYSTROKE = os.getcwd() + \"/Tappy Data/Keystrokes/\"\n",
    "\n",
    "# Keystoke data useful indices\n",
    "DATE = 1 #YYMMDD\n",
    "HAND = 3 # L or R\n",
    "HOLD_TIME = 4 # mmmm.m ms\n",
    "DIRECTION = 5 # LL, LR, LR, RR, S\n",
    "LATENCY_TIME = 6 # ms\n",
    "FLIGHT_TIME = 7 # ms\n",
    "\n",
    "def divideSequence(sequence, n):\n",
    "    for i in range(0, len(sequence), n):\n",
    "        yield sequence[i:i+n]\n",
    "    \n",
    "    \n",
    "def genFileSequences(filepath, birth_year, gender, label):\n",
    "    sequence = []\n",
    "    labels = [label]\n",
    "    \n",
    "    total_flight_time = 0\n",
    "    total_latency_time = 0\n",
    "    total_left_hand = 0\n",
    "    total_keystrokes = 0\n",
    "    \n",
    "    f = open(filepath, 'r')\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "\n",
    "    for line in lines:\n",
    "        total_keystrokes += 1\n",
    "        \n",
    "        line = line.split(\"\\t\")\n",
    "        try:\n",
    "            if birth_year != 0:\n",
    "                age = int(str(line[DATE])[:2]) + 2000\n",
    "                age -= birth_year\n",
    "            else: age = 0\n",
    "\n",
    "            if line[HAND] == \"L\": \n",
    "                hand = 0\n",
    "                total_left_hand += 1\n",
    "            elif line[HAND] == \"R\": hand = 1\n",
    "            elif line[HAND] == \"S\": hand = 2\n",
    "            else: hand = -1\n",
    "\n",
    "            if line[DIRECTION] == \"LL\": direction = 0\n",
    "            elif line[DIRECTION] == \"LR\": direction = 1\n",
    "            elif line[DIRECTION] == \"RR\": direction = 2\n",
    "            elif line[DIRECTION] == \"RL\": direction = 3\n",
    "            elif line[DIRECTION] == \"SS\": direction = 4\n",
    "            elif line[DIRECTION] == \"SL\": direction = 5\n",
    "            else: direction = -1\n",
    "            \n",
    "            try:\n",
    "                age = float(age)\n",
    "                gender = float(gender)\n",
    "                hand = float(hand)\n",
    "                hold_time = float(line[HOLD_TIME])\n",
    "                direction = float(direction)\n",
    "                latency_time = float(line[LATENCY_TIME])\n",
    "                total_latency_time += latency_time\n",
    "                flight_time = float(line[FLIGHT_TIME])\n",
    "                total_flight_time += flight_time\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            #sequence.append([age, gender, hand, hold_time, direction, latency_time, flight_time])\n",
    "            feature = hold_time / 1000 # Decaseconds\n",
    "            sequence.append(feature)\n",
    "            \n",
    "            avg_flight = (total_flight_time / total_keystrokes) / 1000\n",
    "            avg_latency = (total_latency_time / total_keystrokes) / 1000\n",
    "            left_hand_percent = total_left_hand / total_keystrokes\n",
    "            \n",
    "            if avg_flight > 1 or avg_latency > 1 or feature > 1 or left_hand_percent > 1:\n",
    "                #print(avg_flight, avg_latency, feature, left_hand_percent)\n",
    "                continue # Small handful of data we're skipping over # hold time = 8400 minutes\n",
    "                \n",
    "            if avg_flight < 0 or avg_latency < 0 or feature < 0 or left_hand_percent < 0:\n",
    "                #print(avg_flight, avg_latency, feature, left_hand_percent)\n",
    "                continue # None should be negative\n",
    "            \n",
    "            \n",
    "        except ValueError:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "    sequence = list(divideSequence(sequence, 100))\n",
    "    if sequence[-1] != 100: sequence = sequence[:-1]\n",
    "    \n",
    "    # Add non-sequence features\n",
    "    for obs in sequence:\n",
    "        obs.insert(0, avg_latency)\n",
    "        obs.insert(0, avg_flight)\n",
    "        obs.insert(0, left_hand_percent)\n",
    "        obs.insert(0, gender)\n",
    "        obs.insert(0, age / 1000)\n",
    "    \n",
    "    labels = labels * len(sequence)\n",
    "    return sequence, labels\n",
    "\n",
    "def genUserSequences(user, birth_year, gender, label):\n",
    "    user_sequences = []\n",
    "    user_labels = []\n",
    "    \n",
    "    # Get all files by that user and add to np array\n",
    "    #i = 0\n",
    "    for f in os.listdir(PATH_TO_KEYSTROKE):\n",
    "        if f[:10] == user:\n",
    "            filepath = PATH_TO_KEYSTROKE + f\n",
    "            new_sequences, new_labels = (genFileSequences(filepath, \\\n",
    "                                                          birth_year, \\\n",
    "                                                          gender, \\\n",
    "                                                          label))\n",
    "            user_sequences += new_sequences\n",
    "            user_labels += new_labels\n",
    "    \n",
    "    return user_sequences, user_labels\n",
    "\n",
    "def genSequenceData(users):\n",
    "    full_data = []\n",
    "    labels = []\n",
    "    \n",
    "    # Add each user's data to full sequence data\n",
    "    for user in users.index:\n",
    "        \n",
    "        birth_year = users._get_value(user, \"BirthYear\")\n",
    "        gender = users._get_value(user, \"Gender\")\n",
    "        label = users._get_value(user, \"Parkinsons\")\n",
    "        \n",
    "        new_data, new_labels = genUserSequences(user, birth_year, gender, label)\n",
    "        full_data += new_data\n",
    "        labels += new_labels\n",
    "    return full_data, labels\n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "sequence_data, labels = genSequenceData(selected_users)\n",
    "sequence_data = np.asarray(sequence_data)\n",
    "labels = np.asarray(labels)\n",
    "#labels = np.asarray([[label] for label in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.065      0.         0.45254179 0.15155905 0.23952548 0.0625\n",
      " 0.0625     0.0938     0.0703     0.0703     0.0859     0.0938\n",
      " 0.0781     0.0859     0.0781     0.0781     0.0859     0.0781\n",
      " 0.0781     0.0703     0.0703     0.0781     0.0703     0.0703\n",
      " 0.1016     0.0781     0.0703     0.0469     0.0781     0.0859\n",
      " 0.0781     0.0703     0.0859     0.0547     0.0781     0.0625\n",
      " 0.0781     0.125      0.0781     0.1719     0.0703     0.1328\n",
      " 0.1016     0.0781     0.0781     0.0781     0.0703     0.0625\n",
      " 0.0781     0.0625     0.0625     0.0781     0.0703     0.0859\n",
      " 0.0625     0.1016     0.0781     0.0625     0.0703     0.0781\n",
      " 0.0547     0.0703     0.0625     0.0703     0.0781     0.0781\n",
      " 0.0781     0.0938     0.0703     0.0859     0.0938     0.1406\n",
      " 0.0547     0.0781     0.1016     0.0859     0.1016     0.0625\n",
      " 0.0781     0.1094     0.0781     0.1094     0.0625     0.0781\n",
      " 0.0938     0.0703     0.0625     0.0781     0.0625     0.0703\n",
      " 0.0859     0.0703     0.0625     0.0781     0.0781     0.0859\n",
      " 0.1016     0.0781     0.0859     0.0703     0.0703     0.1094\n",
      " 0.0703     0.1016     0.0781    ]\n"
     ]
    }
   ],
   "source": [
    "print(sequence_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sequence in sequence_data:\n",
    "    for observation in sequence:\n",
    "        observation = observation.astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0.065     , 0.        , 0.45254179, ..., 0.0703    , 0.1016    ,\n",
      "        0.0781    ],\n",
      "       [0.065     , 0.        , 0.45254179, ..., 0.0156    , 0.0859    ,\n",
      "        0.0625    ],\n",
      "       [0.065     , 0.        , 0.45254179, ..., 0.0703    , 0.0703    ,\n",
      "        0.0547    ],\n",
      "       ...,\n",
      "       [0.        , 0.        , 0.4736227 , ..., 0.0859    , 0.0781    ,\n",
      "        0.0625    ],\n",
      "       [0.        , 0.        , 0.4736227 , ..., 0.0781    , 0.0776    ,\n",
      "        0.0776    ],\n",
      "       [0.067     , 1.        , 0.50299401, ..., 0.0859    , 0.125     ,\n",
      "        0.1016    ]])\n",
      "(27874, 105)\n",
      "(27874,)\n",
      "[25377  2497]\n"
     ]
    }
   ],
   "source": [
    "pprint(sequence_data)\n",
    "print(sequence_data.shape)\n",
    "print(labels.shape)\n",
    "print(np.bincount(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save/Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_SAVED_DATA = os.getcwd() + \"/Processed Data/\"\n",
    "\n",
    "# Save\n",
    "pickle.dump(sequence_data, open(PATH_TO_SAVED_DATA + \"processed_255.p\", \"wb\"))\n",
    "pickle.dump(labels, open(PATH_TO_SAVED_DATA + \"labels_255.p\", \"wb\"))\n",
    "\n",
    "# Load\n",
    "processed_data = pickle.load(open(PATH_TO_SAVED_DATA + \"processed_255.p\", \"rb\"))\n",
    "labels = pickle.load(open(PATH_TO_SAVED_DATA + \"labels_255.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Data: 11106\n",
      "Training: 7775\n",
      "Testing: 3331\n",
      "Train + Test: 11106\n",
      "Training Split:\n",
      "\t PD = 0: 7043  PD = 1: 732\n",
      "\t 0.9058520900321544 %: 0.09414790996784565 %\n",
      "Testing Split:\n",
      "\t PD = 0: 3073  PD = 1: 258\n",
      "\t 0.9225457820474332 %: 0.0774542179525668 %\n",
      "Training Data size: 7775\n",
      "Testing Data size: 3331\n"
     ]
    }
   ],
   "source": [
    "train_size = math.ceil(len(processed_data) * .7)\n",
    "test_size = math.floor(len(processed_data) * .3)\n",
    "\n",
    "print(\"Total Data:\",len(processed_data))\n",
    "print(\"Training:\",train_size)\n",
    "print(\"Testing:\",test_size)\n",
    "print(\"Train + Test:\",train_size + test_size)\n",
    "\n",
    "\n",
    "training_labels = labels[:train_size]\n",
    "testing_labels = labels[train_size:]\n",
    "\n",
    "train_split = np.bincount(training_labels)\n",
    "print(\"Training Split:\\n\\t\",\"PD = 0:\", train_split[0], \" PD = 1:\", train_split[1])\n",
    "print(\"\\t\", \\\n",
    "      train_split[0] / (train_split[0] + train_split[1]), \\\n",
    "      \"%:\", \\\n",
    "      train_split[1] / (train_split[0] + train_split[1]), \\\n",
    "      \"%\")\n",
    "\n",
    "test_split = np.bincount(testing_labels)\n",
    "print(\"Testing Split:\\n\\t\",\"PD = 0:\",test_split[0],\" PD = 1:\",test_split[1])\n",
    "print(\"\\t\", \\\n",
    "      test_split[0] / (test_split[0] + test_split[1]), \\\n",
    "      \"%:\", \\\n",
    "      test_split[1] / (test_split[0] + test_split[1]), \\\n",
    "      \"%\")\n",
    "\n",
    "training_data = processed_data[:train_size]\n",
    "testing_data = processed_data[train_size:]\n",
    "\n",
    "print(\"Training Data size:\", len(training_data))\n",
    "print(\"Testing Data size:\", len(testing_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_SAVED_DATA = os.getcwd() + \"/Processed Data/\"\n",
    "\n",
    "SAVE = 1\n",
    "\n",
    "# Save\n",
    "if SAVE:\n",
    "    pickle.dump(training_labels, open(PATH_TO_SAVED_DATA + \"train_labels_255.p\", \"wb\"))\n",
    "    pickle.dump(testing_labels, open(PATH_TO_SAVED_DATA + \"test_labels_255.p\", \"wb\"))\n",
    "    pickle.dump(training_data, open(PATH_TO_SAVED_DATA + \"train_data_255.p\", \"wb\"))\n",
    "    pickle.dump(testing_data, open(PATH_TO_SAVED_DATA + \"test_data_255.p\", \"wb\"))\n",
    "# Load\n",
    "else:\n",
    "\n",
    "    training_labels = pickle.load(open(PATH_TO_SAVED_DATA + \"train_labels_1255.p\", \"rb\"))\n",
    "    testing_labels = pickle.load(open(PATH_TO_SAVED_DATA + \"test_labels_255.p\", \"rb\"))\n",
    "    training_data = pickle.load(open(PATH_TO_SAVED_DATA + \"train_data_255.p\", \"rb\"))\n",
    "    testing_data = pickle.load(open(PATH_TO_SAVED_DATA + \"test_data_255.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END: 32938\n",
      "START: 36243\n",
      "END: 37014\n",
      "START: 39511\n",
      "END: 45292\n",
      "START: 46058\n",
      "END: 57945\n",
      "START: 57969\n",
      "END: 72543\n",
      "START: 75167\n",
      "END: 97961\n",
      "START: 100436\n",
      "END: 101054\n",
      "START: 101874\n",
      "END: 118706\n",
      "START: 118717\n",
      "END: 118732\n",
      "START: 118763\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d3271c97455c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpositive_rows\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpositive_rows\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"START:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "positive_rows = []\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == 1:\n",
    "        positive_rows.append(i)\n",
    "        \n",
    "positive_examples = np.asarray([[]])\n",
    "\n",
    "for i in range(len(sequence_data)):\n",
    "    if i not in positive_rows:\n",
    "        if i-1 in positive_rows:\n",
    "            print(\"START:\",i)\n",
    "        if i+1 in positive_rows:\n",
    "            print(\"END:\",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2497, 105)\n",
      "(2497, 105)\n",
      "(4994, 105)\n",
      "(4994,)\n"
     ]
    }
   ],
   "source": [
    "positive_examples = np.asarray(sequence_data[6586:7246])\n",
    "positive_examples = np.append(positive_examples, sequence_data[7398:7896], axis=0)\n",
    "positive_examples = np.append(positive_examples, sequence_data[9050:9202], axis=0)\n",
    "positive_examples = np.append(positive_examples, sequence_data[11574:11578], axis=0)\n",
    "positive_examples = np.append(positive_examples, sequence_data[14485:15007], axis=0)\n",
    "positive_examples = np.append(positive_examples, sequence_data[19550:20040], axis=0)\n",
    "positive_examples = np.append(positive_examples, sequence_data[20159:20322], axis=0)\n",
    "positive_examples = np.append(positive_examples, sequence_data[23684:23686], axis=0)\n",
    "positive_examples = np.append(positive_examples, sequence_data[23689:23695], axis=0)\n",
    "\n",
    "print(positive_examples.shape)\n",
    "\n",
    "negative_examples = np.asarray(sequence_data[0:6586])\n",
    "negative_examples = np.append(negative_examples, sequence_data[7246:7398], axis=0)\n",
    "negative_examples = np.append(negative_examples, sequence_data[7896:9050], axis=0)\n",
    "negative_examples = np.append(negative_examples, sequence_data[9202:11574], axis=0)\n",
    "negative_examples = np.append(negative_examples, sequence_data[11578:14485], axis=0)\n",
    "negative_examples = np.append(negative_examples, sequence_data[15007:19550], axis=0)\n",
    "negative_examples = np.append(negative_examples, sequence_data[20040:20159], axis=0)\n",
    "negative_examples = np.append(negative_examples, sequence_data[20322:23684], axis=0)\n",
    "negative_examples = np.append(negative_examples, sequence_data[23686:23689], axis=0)\n",
    "negative_examples = np.append(negative_examples, sequence_data[23695:], axis=0)\n",
    "\n",
    "np.random.shuffle(negative_examples)\n",
    "\n",
    "negative_examples = negative_examples[:2497]\n",
    "\n",
    "print(negative_examples.shape)\n",
    "\n",
    "balanced_data = np.append(positive_examples, negative_examples, axis=0)\n",
    "balanced_labels = np.ones(2497)\n",
    "balanced_labels = np.append(balanced_labels, np.zeros(2497))\n",
    "\n",
    "print(balanced_data.shape)\n",
    "print(balanced_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3496,)\n",
      "(3496, 105)\n",
      "(1498,)\n",
      "(1498, 105)\n"
     ]
    }
   ],
   "source": [
    "positive_training = positive_examples[0:1748]\n",
    "positive_testing = positive_examples[1748:]\n",
    "negative_training = negative_examples[0:1748]\n",
    "negative_testing = negative_examples[1748:]\n",
    "\n",
    "training_labels = np.ones(1748)\n",
    "training_labels = np.append(training_labels, np.zeros(1748))\n",
    "training = np.append(positive_training, negative_training, axis=0)\n",
    "\n",
    "print(training_labels.shape)\n",
    "print(training.shape)\n",
    "\n",
    "\n",
    "testing_labels = np.ones(749)\n",
    "testing_labels = np.append(testing_labels, np.zeros(749))\n",
    "testing = np.append(positive_testing, negative_testing, axis=0)\n",
    "\n",
    "print(testing_labels.shape)\n",
    "print(testing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_SAVED_DATA = os.getcwd() + \"/Processed Data/\"\n",
    "\n",
    "SAVE = 1\n",
    "\n",
    "# Save\n",
    "if SAVE:\n",
    "    pickle.dump(training_labels, open(PATH_TO_SAVED_DATA + \"train_labels_bal_105.p\", \"wb\"))\n",
    "    pickle.dump(testing_labels, open(PATH_TO_SAVED_DATA + \"test_labels_bal_105.p\", \"wb\"))\n",
    "    pickle.dump(training, open(PATH_TO_SAVED_DATA + \"train_data_bal_105.p\", \"wb\"))\n",
    "    pickle.dump(testing, open(PATH_TO_SAVED_DATA + \"test_data_bal_105.p\", \"wb\"))\n",
    "# Load\n",
    "else:\n",
    "\n",
    "    training_labels = pickle.load(open(PATH_TO_SAVED_DATA + \"train_labels_bal_105.p\", \"rb\"))\n",
    "    testing_labels = pickle.load(open(PATH_TO_SAVED_DATA + \"test_labels_bal_105.p\", \"rb\"))\n",
    "    training = pickle.load(open(PATH_TO_SAVED_DATA + \"train_data_bal_105.p\", \"rb\"))\n",
    "    testing = pickle.load(open(PATH_TO_SAVED_DATA + \"test_data_bal_105.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
